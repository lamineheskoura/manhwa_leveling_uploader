# --- Professional Global Commenting Protocol: ROYAL TITAN ENGINE V14.0 (Full Restoration) Ø³ÙŠØ¯ÙŠ ---
import os
import asyncio
import re
import requests
import time
from DrissionPage import ChromiumPage, ChromiumOptions
from telethon import TelegramClient
from telethon.sessions import MemorySession
from telethon.utils import pack_bot_file_id

# ğŸ” Ø§Ù„Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ù…Ù„ÙƒÙŠØ© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø³ÙŠØ¯ÙŠ
API_ID = 38020317
API_HASH = '941185ea933fd95a990e881fe50a6882'
CHAT_ID = -1003602777623
SITE_API_KEY = "KING_SECRET_KEY_99x"
SITE_API_URL = "https://manhwa-leveling.onrender.com/shadow-throne-99x/api/bulk-sync"

EMBEDDED_TOKENS = [
    '8561369211:AAGAN-YVY03WgbBDfeQmbh4EvxBD_SWKlzA',
    '8287317424:AAGwuglZT6fK8aDUjgYN4cRMfO6a0INlgK8',
    '8321405841:AAGbRHcmjMm9i2l0obI0k3skMmO9zbpzVOE'
]

SB_URL = (os.getenv("SB_URL") or "").strip().rstrip('/')
SB_KEY = (os.getenv("SB_KEY") or "").strip()
HEADERS = {"apikey": SB_KEY, "Authorization": f"Bearer {SB_KEY}", "Content-Type": "application/json"}

# --- Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¨Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø³ÙŠØ¯ÙŠ ---

def supabase_get_task():
    try:
        url = f"{SB_URL}/rest/v1/manhwa_tasks?status=eq.idle&order=priority.desc&limit=1"
        r = requests.get(url, headers=HEADERS, timeout=20)
        return r.json() if r.status_code == 200 else []
    except: return []

def supabase_update_task(task_id, payload):
    try:
        url = f"{SB_URL}/rest/v1/manhwa_tasks?id=eq.{task_id}"
        requests.patch(url, headers=HEADERS, json=payload, timeout=20)
    except: pass

class ManhwaArchitect:
    def __init__(self):
        self.co = ChromiumOptions()
        self.co.set_argument('--headless')
        self.co.set_argument('--no-sandbox')
        self.co.set_argument('--disable-gpu')
        self.co.set_user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36')
        self.co.set_argument('--disable-blink-features=AutomationControlled')
        self.page = ChromiumPage(self.co)

    def bypass_cloudflare(self, url):
        """Ø§Ø®ØªØ±Ø§Ù‚ Ø§Ù„Ø¯Ø±ÙˆØ¹ Ù…Ø¹ Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù†Ø´Ø§Ø· Ø³ÙŠØ¯ÙŠ"""
        print(f"ğŸŒ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„: {url}")
        self.page.get(url)
        for i in range(1, 15):
            title = self.page.title
            if "Just a moment" not in title and "Cloudflare" not in title:
                print(f"âœ… ØªÙ… Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚. Ø¬Ø§Ø±ÙŠ ØªØ­ÙÙŠØ² Ø§Ù„ØµÙˆØ±...")
                # ØªÙ…Ø±ÙŠØ± Ø°ÙƒÙŠ Ø³ÙŠØ¯ÙŠ Ù„ÙÙƒ Ø§Ù„Ù‚ÙÙ„ Ø¹Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„ÙƒØ³ÙˆÙ„Ø© (Lazy Load)
                for _ in range(4):
                    self.page.scroll.down(1200)
                    time.sleep(1)
                return True
            print(f"â³ Ø§Ù„Ø¯Ø±Ø¹ Ù†Ø´Ø· ({i})...")
            time.sleep(3)
        return False

    def extract_precise_images(self):
        """Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¹Ù† Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø³ÙŠØ¯ÙŠ"""
        links = []
        # Ù…ØµÙÙˆÙØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø§Øª Ø§Ù„Ù‚ÙˆÙŠØ© Ù…Ù† Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø³ÙŠØ¯ÙŠ
        selectors = [
            '.reading-content img', '.main-col img', '.wp-manga-chapter-img img',
            '.reader-area img', '.vung-doc img', '#chapter-video-frame img'
        ]
        
        for s in selectors:
            imgs = self.page.eles(s)
            for img in imgs:
                src = img.attr('data-src') or img.attr('data-lazy-src') or img.attr('src') or img.attr('data-original')
                if src and 'http' in src and not any(x in src.lower() for x in ['logo', 'banner', 'avatar', 'icon']):
                    links.append(src)
        
        # Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø§ØªØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù€ HTML Ø³ÙŠØ¯ÙŠ
        if not links:
            links = re.findall(r'https?://[^\s"\'<>]+?\.(?:webp|jpg|png|jpeg)', self.page.html)
            links = [l for l in links if not any(x in l.lower() for x in ['logo', 'icon', 'theme'])]
            
        return list(dict.fromkeys(links))

    def find_next_chapter(self):
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„ÙØµÙ„ Ø§Ù„ØªØ§Ù„ÙŠ Ø³ÙŠØ¯ÙŠ"""
        btn = self.page.ele('.next_page') or self.page.ele('text:Ø§Ù„ØªØ§Ù„ÙŠ') or self.page.ele('text:Next')
        return btn.attr('href') if btn and btn.attr('href') else None

# --- Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù‡Ø¬ÙˆÙ… Ø³ÙŠØ¯ÙŠ ---

async def start_royal_mission():
    tasks = supabase_get_task()
    if not tasks: 
        print("ğŸ“­ Ø§Ù„Ø³Ø§Ø­Ø© Ø®Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù… Ø³ÙŠØ¯ÙŠ.")
        return
    
    task = tasks[0]
    task_id = task['id']
    print(f"âš”ï¸ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ù„Ù€: {task['name']}...")

    # Ù†Ø¸Ø§Ù… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙØ±Ø³Ø§Ù† Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚ Ø³ÙŠØ¯ÙŠ
    raw_tokens = os.getenv("BOT_TOKENS") or ""
    all_tokens = [t.strip() for t in raw_tokens.split(',') if t.strip()]
    if not all_tokens: all_tokens = EMBEDDED_TOKENS
    
    client = None
    for token in all_tokens:
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù…Ù†Ø¹ Database Locked Ø³ÙŠØ¯ÙŠ
            temp_client = TelegramClient(MemorySession(), API_ID, API_HASH)
            await temp_client.start(bot_token=token)
            client = temp_client
            print("âœ… Ø§Ù„ÙØ§Ø±Ø³ Ø¬Ø§Ù‡Ø².")
            break
        except: continue

    if not client: return

    architect = ManhwaArchitect()
    try:
        curr_url = task['source_url']
        last_ch = float(task['last_chapter'])
        target_id = task['target_id']

        # Ø­Ù„Ù‚Ø© Ø§Ù„ØºØ²Ùˆ Ø§Ù„Ù…Ø³ØªÙ…Ø± (Ø±ÙØ¹ 5 ÙØµÙˆÙ„ Ù…ØªØªØ§Ù„ÙŠØ© Ø³ÙŠØ¯ÙŠ)
        for mission_count in range(5):
            if not architect.bypass_cloudflare(curr_url): break

            images = architect.extract_precise_images()
            print(f"ğŸ“¸ ÙØµÙ„ {last_ch + 1}: ØªÙ… Ø±ØµØ¯ {len(images)} Ù‡Ø¯Ù.")

            if not images: break

            supabase_update_task(task_id, {"status": "uploading"})
            file_ids = []
            
            # Ø±ÙØ¹ Ø§Ù„ØµÙˆØ± Ø³ÙŠØ¯ÙŠ
            for i, img in enumerate(images, 1):
                try:
                    sent = await client.send_file(CHAT_ID, img, force_document=True)
                    file_ids.append(str(pack_bot_file_id(sent.media.document)))
                    if i % 10 == 0: print(f"ğŸš€ ØªÙ… Ø±ÙØ¹ {i} ØµÙˆØ±...")
                except: continue

            if file_ids:
                new_ch = last_ch + 1
                payload = {"manhwa_id": int(target_id), "chapter_number": new_ch, "image_ids": file_ids, "is_premium": False}
                res = requests.post(SITE_API_URL, json=payload, headers={"X-API-KEY": SITE_API_KEY}, timeout=60)
                
                if res.status_code == 200:
                    print(f"ğŸ† Ù†ØµØ± Ù…Ù„ÙƒÙŠ! ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ÙØµÙ„ {new_ch}")
                    last_ch = new_ch
                    next_url = architect.find_next_chapter()
                    
                    # ØªØ­Ø¯ÙŠØ« Ø³ÙˆØ¨Ø§Ø¨ÙŠØ² Ø³ÙŠØ¯ÙŠ Ù„Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„ÙØµÙ„ Ø§Ù„ØªØ§Ù„ÙŠ
                    supabase_update_task(task_id, {
                        "last_chapter": new_ch,
                        "status": "idle",
                        "source_url": next_url if next_url else curr_url
                    })
                    
                    if next_url: curr_url = next_url
                    else: 
                        print("ğŸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙØµÙˆÙ„ ØªØ§Ù„ÙŠØ© Ø­Ø§Ù„ÙŠØ§Ù‹.")
                        break
                else: break
            else: break
            
    except Exception as e:
        print(f"ğŸš¨ Ø®Ø·Ø£ Ù…ÙŠØ¯Ø§Ù†ÙŠ: {e}")
    finally:
        if client: await client.disconnect()
        architect.page.quit()

if __name__ == "__main__":
    asyncio.run(start_royal_mission())